{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adf02f0-6fa0-4ef5-aba8-fa3df1f9e035",
   "metadata": {},
   "source": [
    "# Natural Language Tool Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbea8295-622f-4bc2-8b4c-31e495c931a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/robertwrobel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd9e6fd-eb81-4147-ae37-cc5a9be21315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808d294c-1980-426b-a33f-5a4d19336c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love visiting the beach\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.6369}\n",
      "Text: I hate it when my phone battery dies.\n",
      "Sentiment: {'neg': 0.381, 'neu': 0.619, 'pos': 0.0, 'compound': -0.5719}\n",
      "Text: Today is a terrible day.\n",
      "Sentiment: {'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "Text: Wow, this is an amazing movie!\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.336, 'pos': 0.664, 'compound': 0.8356}\n",
      "Text: I hate you more than I've ever hated anyone!\n",
      "Sentiment: {'neg': 0.577, 'neu': 0.423, 'pos': 0.0, 'compound': -0.8478}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = [\n",
    "    \"I love visiting the beach\",\n",
    "    \"I hate it when my phone battery dies.\",\n",
    "    \"Today is a terrible day.\",\n",
    "    \"Wow, this is an amazing movie!\",\n",
    "    \"I hate you more than I've ever hated anyone!\"\n",
    "]\n",
    "\n",
    "#VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "for text in texts:\n",
    "    print(\"Text:\", text)\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f9bb386-a0fe-40b8-8ee8-6ab2d79c9004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'there',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'doing',\n",
       " 'fine',\n",
       " ',',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'asking',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello there! How are you? I'm doing fine, thanks for asking.\"\n",
    "sent_tokenize(text)\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2d7d117-67f3-4cec-bb55-b0abeed3f5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('quick', 'JJ'),\n",
       " ('brown', 'NN'),\n",
       " ('fox', 'NN'),\n",
       " ('jumps', 'VBZ'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lazy', 'JJ'),\n",
       " ('dog', 'NN')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = word_tokenize(text)\n",
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d368986d-349b-4e0f-9de0-7fce4b6167f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  announced/VBD\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  (ORGANIZATION iPhone/NN)\n",
      "  and/CC\n",
      "  (PERSON Bob/NNP)\n",
      "  did/VBD\n",
      "  n't/RB\n",
      "  care/VB\n",
      "  one/CD\n",
      "  bit/NN\n",
      "  because/IN\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  too/RB\n",
      "  busy/JJ\n",
      "  teaching/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Webster/NNP University/NNP)\n",
      "  in/IN\n",
      "  (GPE St./NNP)\n",
      "  Louis/NNP)\n"
     ]
    }
   ],
   "source": [
    "text = \"Apple announced the new iPhone and Bob didn't care one bit because he was too busy teaching at Webster University in St. Louis\"\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "entities = ne_chunk(tags)\n",
    "type(entities)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97f72306-948e-4410-991d-7a898166222f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized: run\n",
      "Stemmed: run\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "word = \"running\"\n",
    "print(\"Lemmatized:\", lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "print(\"Stemmed:\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78446e5e-4bcd-4248-959a-c02c19bf4460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\", \"Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\", 'So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.', \"There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\", 'Oh dear!', \"I shall be late!'\", '(when she thought it over afterwards, it\\noccurred to her that she ought to have wondered at this, but at the time\\nit all seemed quite natural); but']\n"
     ]
    }
   ],
   "source": [
    "sample_text = gutenberg.raw('carroll-alice.txt')\n",
    "sample_sentences = sent_tokenize(sample_text[:1000])\n",
    "print(sample_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
